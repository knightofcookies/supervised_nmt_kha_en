{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sentencepiece as spm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "\n",
    "en_model_prefix = \"en_multi30k_word\"\n",
    "de_model_prefix = \"de_multi30k_word\"\n",
    "\n",
    "en_sp = spm.SentencePieceProcessor()\n",
    "de_sp = spm.SentencePieceProcessor()\n",
    "\n",
    "en_sp.Load(f\"{en_model_prefix}.model\")\n",
    "de_sp.Load(f\"{de_model_prefix}.model\")\n",
    "\n",
    "word_vec_size = 512\n",
    "en_vocab_size = en_sp.GetPieceSize()\n",
    "de_vocab_size = de_sp.GetPieceSize()\n",
    "en_word_padding_idx = en_sp.pad_id()\n",
    "de_word_padding_idx = de_sp.pad_id()\n",
    "dropout = 0.1\n",
    "position_encoding = True\n",
    "MAX_LENGTH = 100\n",
    "\n",
    "def numericalize(text, tokenizer):\n",
    "    ids = tokenizer.EncodeAsIds(text)\n",
    "    return torch.tensor(ids)\n",
    "\n",
    "def pad_sequences(src, tgt):\n",
    "    max_length = max(max(len(s) for s in src), max(len(t) for t in tgt))\n",
    "\n",
    "    # Pad the sequences to the maximum length\n",
    "    src_padded = [\n",
    "        torch.cat([s, torch.tensor([en_word_padding_idx] * (max_length - len(s)), dtype=torch.long)])\n",
    "        for s in src\n",
    "    ]\n",
    "    tgt_padded = [\n",
    "        torch.cat([t, torch.tensor([de_word_padding_idx] * (max_length - len(t)), dtype=torch.long)])\n",
    "        for t in tgt\n",
    "    ]\n",
    "\n",
    "    # Convert to tensors\n",
    "    src_padded = torch.stack(src_padded)\n",
    "    tgt_padded = torch.stack(tgt_padded)\n",
    "    \n",
    "\n",
    "    return src_padded, tgt_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=DEVICE).fill_(de_sp.bos_id())\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(encoder_outputs.shape[1]):\n",
    "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=DEVICE).fill_(de_sp.bos_id())\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(encoder_outputs.shape[1]):\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded =  self.dropout(self.embedding(input))\n",
    "\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_en_to_de(\n",
    "    encoder,\n",
    "    decoder,\n",
    "    en_sp,\n",
    "    de_sp,\n",
    "    learning_rate=0.001,\n",
    "    num_epochs=10,\n",
    "    batch_size=32,\n",
    "):\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss().to(DEVICE)\n",
    "\n",
    "    def load_data(en_filepath, de_filepath):\n",
    "        en_data = []\n",
    "        de_data = []\n",
    "        with open(en_filepath, \"r\", encoding=\"utf-8\") as en_f, open(\n",
    "            de_filepath, \"r\", encoding=\"utf-8\"\n",
    "        ) as de_f:\n",
    "            for en_line, de_line in zip(en_f, de_f):\n",
    "                en_data.append(en_line.strip())\n",
    "                de_data.append(de_line.strip())\n",
    "        return en_data, de_data\n",
    "\n",
    "    en_train, de_train = load_data(\"multi30k_train_en.txt\", \"multi30k_train_de.txt\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        total_loss = 0\n",
    "\n",
    "        data = list(zip(en_train, de_train))\n",
    "        random.shuffle(data)\n",
    "        en_train, de_train = zip(*data)\n",
    "\n",
    "        for i in range(0, len(en_train), batch_size):\n",
    "            en_batch = en_train[i : i + batch_size]\n",
    "            de_batch = de_train[i : i + batch_size]\n",
    "\n",
    "            # Numericalize and pad the *entire batch*\n",
    "            en_numericalized = [numericalize(text, en_sp) for text in en_batch]\n",
    "            de_numericalized = [numericalize(text, de_sp) for text in de_batch]\n",
    "\n",
    "\n",
    "            ip, op = pad_sequences(en_numericalized, de_numericalized)\n",
    "\n",
    "            input_tensor = ip.to(DEVICE)\n",
    "            target_tensor = op.to(DEVICE)\n",
    "            \n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "\n",
    "            encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "\n",
    "            decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "            loss = criterion(\n",
    "                decoder_outputs.view(-1, decoder_outputs.size(-1)), target_tensor.view(-1)\n",
    "            )\n",
    "            loss.backward()\n",
    "\n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "\n",
    "            total_loss += (loss.item() / len(en_train))\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_time\n",
    "\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}, Time: {epoch_time:.2f}s\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, en_sp, de_sp):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = numericalize(sentence, en_sp).view(1, -1)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == de_sp.eos_id():\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            decoded_words.append(de_sp.IdToPiece(idx.item()))\n",
    "    return decoded_words, decoder_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = [\"a young man in a black and yellow jacket is gazing at something and smiling .\", \"ein junger mann in einer schwarz-gelben jacke blickt etwas an und lÃ¤chelt .\"]\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], en_sp, de_sp)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(en_vocab_size, hidden_size=512).to(DEVICE)\n",
    "decoder = AttnDecoderRNN(hidden_size=512, output_size=de_vocab_size).to(DEVICE)\n",
    "\n",
    "train_en_to_de(encoder, decoder, en_sp, de_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(encoder, decoder, input_sentence, en_sp, de_sp)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions[0, :len(output_words), :])\n",
    "\n",
    "\n",
    "evaluateAndShowAttention('il n est pas aussi grand que son pere')\n",
    "\n",
    "evaluateAndShowAttention('je suis trop fatigue pour conduire')\n",
    "\n",
    "evaluateAndShowAttention('je suis desole si c est une question idiote')\n",
    "\n",
    "evaluateAndShowAttention('je suis reellement fiere de vous')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
